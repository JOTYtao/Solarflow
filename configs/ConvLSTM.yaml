# @package _global_

# specify here default training configuration
seed: 42
work_dir: ''
model_name: ConvLSTM
# path to folder with data
data_dir: ${work_dir}/data
# use `python run.py debug=true` for easy debugging!
# this will run 1 train, val and test loop with only 1 batch
# equivalent to running `python run.py trainer.fast_dev_run=true`
# (this is placed here just for easier access from command line)
debug: False
mode: train
pretrained_ckpt_path: 
# pretty print config at the start of the run using Rich library
print_config: True

# disable python warnings if they annoy you
ignore_warnings: True
trainer:
  _target_: pytorch_lightning.Trainer
  default_root_dir: ${work_dir}/checkpoints/${model_name}
  gradient_clip_val: 1.0
  devices: 1
  accelerator: "gpu"
  max_epochs: 500
  min_epochs: 1
  max_steps: 200000
  min_steps: 2000
  accumulate_grad_batches: 1
  check_val_every_n_epoch: 1
  num_sanity_val_steps: 2
  enable_checkpointing: True
  enable_progress_bar: True
  log_every_n_steps: 100
  precision: 16
  sync_batchnorm: False
  benchmark: True
  deterministic: False
  fast_dev_run: False
  overfit_batches: 0.0
  enable_model_summary: True
  strategy: "auto"
model:
  _target_: models.conv_lstm.EncoderDecoderConvLSTM
  input_channels: 9
  out_channels: 1
  forecast_steps: 8
  lr: 0.001
  visualize: True
  lr_scheduler_mode: "plateau"
  hidden_dim: 128
  conv_type: "antialiased"
  max_epochs: 500
  save_dir: ${work_dir}/results/${model_name}

datamodule:
  _target_: data.datamodules.SIS_DataModule
  dataset:
    "data_path": ${data_dir}
    "years": {
      "train": [ 2017, 2018, 2019, 2020 ],
      "val": [ 2021 ],
      "test": [ 2022 ]}
    "input_len": 8
    "pred_len": 8
    "stride": 1
    "use_possible_starts": True
  "batch_size": 16
  "num_workers": 10
  "pin_memory": True

callbacks:
  model_checkpoint:
    _target_: pytorch_lightning.callbacks.ModelCheckpoint
    monitor: "val/loss" # name of the logged metric which determines when model is improving
    save_top_k: 1 # save k best models (determined by above metric)
    save_last: True # additionaly always save model from last epoch
    save_weights_only: True # Save only weights and hyperparams, makes smaller and doesn't include callbacks/optimizer/etc. Generally, this should be True, as haven't really been restarting training runs much
    mode: "min" # can be "max" or "min"
    verbose: False
    dirpath: ${work_dir}/checkpoints/${model_name}
    filename: "epoch_{epoch:03d}-val_loss_{val/loss:.4f}"

  early_stopping:
    _target_: pytorch_lightning.callbacks.EarlyStopping
    monitor: "val/loss" # name of the logged metric which determines when model is improving
    patience: 5 # how many epochs of not improving until training stops
    mode: "min" # can be "max" or "min"
    min_delta: 1e-3  # minimum change in the monitored metric needed to qualify as an improvement
    verbose: True
  lr_monitor:
    _target_: pytorch_lightning.callbacks.LearningRateMonitor
    logging_interval: "epoch"

  model_logging:
    _target_: core.callbacks.NeptuneModelLogger
    model_name: ${model_name}
logger:
    # https://neptune.ai

  neptune:
    _target_: neptune.new.integrations.pytorch_lightning.NeptuneLogger
    api_key: "eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJkZmE1MDA2Mi1lNDE0LTRmYjYtYjU0YS0yY2E5NTNjODM3M2QifQ==" # api key is loaded from environment variable
    project: "joty/ConvLSTM-SIS"
    prefix: ""
    name: "Sat"

hparams_search:
  # @package _global_

  # example hyperparameter optimization of some experiment with Optuna:
  # python run.py -m hparams_search=mnist_optuna experiment=example_simple
  # python run.py -m hparams_search=mnist_optuna experiment=example_simple hydra.sweeper.n_trials=30
  # python run.py -m hparams_search=mnist_optuna experiment=example_simple logger=wandb

  defaults:
    - override /hydra/sweeper: optuna

  # choose metric which will be optimized by Optuna
  optimized_metric: "val/loss"

  hydra:
    # here we define Optuna hyperparameter search
    # it optimizes for value returned from function with @hydra.main decorator
    # learn more here: https://hydra.cc/docs/next/plugins/optuna_sweeper
    sweeper:
      _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
      storage: null
      study_name: null
      n_jobs: 1

      # 'minimize' or 'maximize' the objective
      direction: minimize

      # number of experiments that will be executed
      n_trials: 20

      # choose Optuna hyperparameter sampler
      # learn more here: https://optuna.readthedocs.io/en/stable/reference/samplers.html
      sampler:
        _target_: optuna.samplers.TPESampler
        seed: 12345
        consider_prior: true
        prior_weight: 1.0
        consider_magic_clip: true
        consider_endpoints: false
        n_startup_trials: 10
        n_ei_candidates: 24
        multivariate: false
        warn_independent_sampling: true

      # define range of hyperparameters
      search_space:
        model.learning_rate:
          type: float
          low: 0.0001
          high: 0.2
        model.num_layers:
          type: categorical
          choices: [ 8, 16, 32, 64, 128 ]
hydra:
  run:
    dir: ${work_dir}/logs/runs/${now:%Y-%m-%d}/${now:%H-%M-%S}
  sweep:
    dir: ${work_dir}/logs/multiruns/${now:%Y-%m-%d_%H-%M-%S}
    subdir: ${hydra.job.num}

  # you can set here environment variables that are universal for all users
  # for system specific variables (like data paths) it's better to use .env file!
  job:
    env_set:
      EXAMPLE_VAR: "example_value"

paths:
  output_dir: ${work_dir}/outputs/${model_name}
  log_dir: ${work_dir}/logs/${model_name}